import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from matplotlib import pyplot as plt
from matplotlib.pyplot import figure
import seaborn as sns
from tensorflow.keras.callbacks import History
from tensorflow.keras.optimizers import SGD

from google.colab import drive
drive.mount('/content/drive')

train_dir = '/content/drive/MyDrive/Segmentation/Training'
test_dir = '/content/drive/MyDrive/Segmentation/Testing'
val_dir = '/content/drive/MyDrive/Segmentation/Validation'
image_size = (224, 224)
batch_size = 32
num_classes = 3

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

for layer in vgg_base.layers:
    layer.trainable = False

x = Flatten()(vgg_base.output)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=vgg_base.input, outputs=output)

model.summary()

model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

sns.set_theme()
sns.set_context("poster")
figure(figsize=(25, 25), dpi=100)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

model.save("/content/drive/MyDrive/leaf.h5")

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)

from sklearn.metrics import confusion_matrix
# ... (your previous code)
predictions = model.predict(val_generator)
# Get predictions and true labels from generators
y_true = val_generator.classes
y_pred = np.argmax(predictions, axis=1)
# Calculate confusion matrix
cm = confusion_matrix(y_true, y_pred)
# Calculate accuracy
accuracy = np.sum(np.diag(cm)) / np.sum(cm)
accuracy_percent = accuracy * 100
accuracy_percent_formatted = f"{accuracy_percent:.2f}%"
# Calculate precision, recall, and F1-score (optional)
precision = np.zeros(cm.shape[0])
recall = np.zeros(cm.shape[0])
f1_score = np.zeros(cm.shape[0])
for i in range(cm.shape[0]):
    if np.sum(cm[i, :]) > 0:  # Avoid division by zero
        precision[i] = cm[i, i] / np.sum(cm[i, :])
    if np.sum(cm[:, i]) > 0:
        recall[i] = cm[i, i] / np.sum(cm[:, i])
    if precision[i] > 0 and recall[i] > 0:
        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])
# Print results
print("Confusion Matrix:\n", cm)
print("Accuracy:", accuracy_percent_formatted)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1_score)  # Optional
# ... (your remaining code for saving the model and prediction,Â etc.)
